---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ollama
  labels:
    app: ollama
spec:
  serviceName: ollama
  replicas: 3
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: kubernetes.io/hostname
                    operator: In
                    values:
                      - opi01
                      - opi02
                      - opi03
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - ollama
              topologyKey: kubernetes.io/hostname
      containers:
        - name: ollama
          image: ollama/ollama:latest
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 11434
              name: api
              protocol: TCP
          env:
            - name: OLLAMA_HOST
              value: "0.0.0.0:11434"
            - name: OLLAMA_MODELS
              value: "/root/.ollama/models"
          resources:
            requests:
              cpu: 500m
              memory: 3Gi
            limits:
              cpu: 2000m
              memory: 6Gi
          volumeMounts:
            - mountPath: /root/.ollama
              name: ollama-models
          lifecycle:
            postStart:
              exec:
                command:
                  - /bin/sh
                  - -c
                  - |
                    echo "Waiting for Ollama API to be ready..."
                    for i in {1..60}; do
                      if curl -f http://localhost:11434/api/tags > /dev/null 2>&1; then
                        echo "Ollama API is ready!"
                        break
                      fi
                      echo "Attempt $i: API not ready yet"
                      sleep 2
                    done
                    echo "Pulling TinyLlama model in background..."
                    curl -X POST http://localhost:11434/api/pull \
                      -H "Content-Type: application/json" \
                      -d '{"name": "tinyllama"}' \
                      --max-time 600 \
                      > /dev/null 2>&1 &
                    echo "Model pull request sent"
          livenessProbe:
            httpGet:
              path: /api/tags
              port: 11434
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /api/tags
              port: 11434
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 3
            failureThreshold: 2
  volumeClaimTemplates:
    - metadata:
        name: ollama-models
      spec:
        accessModes:
          - ReadWriteOnce
        storageClassName: openebs-hostpath
        resources:
          requests:
            storage: 20Gi
